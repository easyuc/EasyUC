\def\IsDraft{} % set for draft version

\documentclass{article}[12pt]

% == Import Packages ==
\usepackage[margin=1in]{geometry} % Page dimensions
\usepackage{amsmath} % Math formulas
\usepackage{xcolor} % Colors
\usepackage{hyperref} % Hyperlinks
\usepackage{cleveref} % Clever References

% == Inline comments ==
\ifdefined\IsDraft
\newcommand{\authnote}[2]{[{\color{red}\textbf{#1:}}茔镬矧忪蹂２蔟苠祗茴鬻泔眄犷潲茚豸桀雉妪鄄蓰苕茴鬻泔眄犷潲茚祆妁郾蓰茚豸桀雉妍领戾１茴鬻泔眄犷潲茼彗犷郾蓰茚豸桀雉妍湾玑铨１茴鬻泔眄犷潲茼狴犷臊郾蓰茚豸桀雉妍歪犷臊１茴鬻泔眄犷潲茯犷郾蓰茚豸桀雉妍裔铨１浇蔑溴箢轲疱趔浇娘泱梏麴函翦滹惝铄舣翦礞溟篝滹惘灬翦扉篝轭珞扉篝轭珞痄荃箦疳汶徵妍扉篝轭珞莒篝溴骈铄灬铉踽珏遽簌泸痿盹蝈脲黠蜾蠼戾眄岈盹漉戾痱镢鲠颥蝈趱蝾殒屐箦蝈聃轵瀣轫痫螋豉疱镳狲轱憩痱邃箦泗轱瞵祜汜忑腻骈铄遽簌泸痿孱鲩蝻铐孱莒篝铄麇铞轵镱礤铘遽簌泸痿郾蒇茴镩钿孱茼轭轲徵妍莒轭鬻殇翳荟箴徙妍爱弟忉箦扉铄箅轲莒篝箦酐渝轭扉铄泔溴疳蜥礤翦颞螬忉箝泱豉戾杰箜犰飕痱轭麒镬扉篝轭箜犰脲黠蜾篝戾杰泔祜螓忪徙臊茆骟弪殄蟋怙熹忪徙脲黠蜾殇孱糸骈弪篝戾浆铒翳轭栳痧孱泔眄孱趔豉戾杰泔祜螓珧狴麒轸泔眄孱趔篝蜷铉篝戾杰趑驷黹禊豉疱黩轸弪豉疱骘篝蜷铉箬秣篝蜷铉箴徙弩芥犰箦铒箴邈獒篝蜷铉箴徙弩翎怏辁褰铂翎怏豉疱箦狍箴徙弩骝犴褰箝铉戾扉铄徕秭犷忮祜泔溴箢轲疱趔怛遽腱轭弩紧蝓瀣怛遽扉铄麒孱翳弪濮秭弪骒秣灬铉踽珏藉狍泸痿盹蝈泔眄孱艚垲蓰í溴骈铄泔眄孱溴扉黹翦蝮扉翦蜥翦禁 {$\sim$}{1},				% prettier tilde
	}
}{\endminipage}

\newcommand{\code}[1]{\texttt{#1}}%inline code

% == Messages ==
\newcommand{\OpenMsg}{\mathsf{Open}}
\newcommand{\CommitMsg}{\mathsf{Commit}}

% PKE
\newcommand{\PKE}{\mathsf{PKE}}
\newcommand{\Gen}{\mathsf{Gen}}
\newcommand{\Enc}{\mathsf{Enc}}
\newcommand{\Dec}{\mathsf{Dec}}
\newcommand{\Indcpa}{\mathsf{INDCPA}}
\newcommand{\IndcpaGM}{\mathcal{C}} % the game master (i.e. challenger) for the indcpa game.

% CFPTP
\newcommand{\CFPTP}{\mathsf{CFPTP}}
\newcommand{\Forw}{\mathsf{Forw}}
\newcommand{\Back}{\mathsf{Back}}
\newcommand{\ForwKey}{fk}
\newcommand{\BackKey}{bk}
\newcommand{\Domain}{D}


% == Proof ==
% Entities
\newcommand{\Sim}{{\mathsf{Sim}}} % Simulator
\newcommand{\Adversary}{{\mathsf{Adv}}} % Adversary
\newcommand{\Environment}{{\mathcal{Z}}} % Environment
\newcommand{\CFPTPAdversary}{{\Adversary_\CFPTP}}
\newcommand{\IndcpaAdversary}{{\Adversary_\Indcpa}}

% Hybrids
\newcommand{\Ideal}{{\mathsf{Ideal}}}
\newcommand{\Hyb}{{\mathsf{Hyb}}}
\newcommand{\Real}{{\mathsf{Real}}}


% == Document title ==
\title{Proof sketch for \cite{CanettiF01}'s static protocol}
\author{Megan Chen}
\date{\today}

\begin{document}
\maketitle
\tableofcontents

\section{Preliminaries}

\section{Proof Strategy}
The proof proceeed via a sequence of games.

\subsection{Sequence of Hybrids}
Define $\Hyb$ to work exactly as the $\Ideal$ game, except that if the committer is \underline{not} corrupted, the simulator $\Sim_{\Hyb}$ learns the real committed bit $b$ and sends the actual commit string $(y, c_0, c_1)$.
\begin{enumerate}
	\item\label{hyb:1} $\Real \approx \Hyb$ - reduction to claw-free pair of trapdoor permutations (CFPTP).
	\item\label{hyb:2} $\Hyb \approx \Ideal$ - reduction to IND-CPA security of PKE
\end{enumerate}

The overall goal is the show that

\begin{easycrypt}
lemma REAL_IDEAL &m :
`|Pr[REAL().main() @ &m : res] - Pr[Ideal().main() @ &m : res]|
<= Pr[CFP_Game(CFAdv).main() @ &m : res]
   + `|Pr[INDCPA_0(Adv).main() @ &m : res] - Pr[INDCPA_1(Adv).main() @ &m : res]|.
\end{easycrypt}

\section{Hybrid \ref{hyb:1}: Showing $\Real \approx \Hyb$}

\subsection{Overview}
We use up to bad reasoning to show an upper bound on the environment $\Environment$'s ability to distinguish between $\Real$ and $\Hyb$. In particular, the only difference in $\Environment$'s view between $\Real$ and $\Hyb$ is when $\Sim_\Hyb$ aborts. In detail, $\Sim_\Hyb$ aborts when it receives a $\CommitMsg$ message $(y, c_0, c_1)$ and an $\OpenMsg$ message $(b', x', r)$ such that
\begin{itemize}
	\item $x' = \CFPTP.\Back_{b'}(y)$
	\item $c_{b'} = \PKE.\Enc_{pk}(x)$
	\item $b' \ne b$ where $b$ is the real committed bit.
\end{itemize}

This is a ``bad event'' because $\Sim_\Hyb$ found a claw for the pair of trapdoor permutations. Recall that in $\Hyb$, the $y$ in the $\CommitMsg$ message is $y = \CFPTP.\Forw_{b}(x)$, so the claw is $x, x'$.

Hence, to we upper-bound $\Adversary$'s distinguishing advantage via defining an adversary $\CFPTPAdversary$ that finds claws for a given CFPTP.

Given a CFPTP forward key $\ForwKey$, $\Adversary_{\Hyb}$ with input $y$ (from the permutation domain $\Domain$) works as follows:
\begin{itemize}
	\item Act as the simulator $\Sim_\Hyb$.
	\item If $\Sim_\Hyb$ aborts, output $x, x'$.
\end{itemize}
This succeeds with the same probability $\Sim_\Hyb$ aborts.

\subsection{Easycrypt Proof}
Since $\Environment$'s view is identical between $\Real$ and $\Hyb$ except when $\Sim_\Hyb$ aborts, most of the easycrypt proof should be a series of rewritings and transformations that do not give $\Environment$ any distinguishing advantage. Then, we can upper bound $\Environment$'s distinguishing advantage by the probability of the ``bad event'', i.e. when $\Sim_\Hyb$ finds a claw for the pair of trapdoor permutations. We can express this via the following lemma:

\begin{easycrypt}
lemma REAL_HYB &m :
`|Pr[REAL.main() @ &m : res] - Pr[HYB.main() @ &m : res]|
<= Pr[CFP_Game(CFAdv).main() @ &m : res].
\end{easycrypt}

We also need the following helper lemmas:

\begin{easycrypt}
lemma REAL_HYB_main &m :
equiv[REAL.main  HYB.main : true => (* If Sim_Hyb didn't abort, then programs are equivalent. *)].

lemma HYB_main_abort_ub &m :
Pr[HYB.main() @ &m : (* Sim_Hyb aborts *)] <= Pr[CFP_Game(CFAdv).main() @ &m : res].
\end{easycrypt}

To prove this, we define a claw-finding adversary. First, in ${\sf Cfptp.ec}$, we defined the claw-free pair game is defined as

\begin{easycrypt}
module CFP_Game(Cf: ClawFinder) = {
	proc main(): bool = {
		var fk: fkey; var bk: bkey;
		var x0, x1 : D;

		(fk, bk) <$ keygen;             (* Generates keys for CFPTP. $*)
		(x0, x1) <@ Cf.find_claw(fk);   (* Find any claw for the CFPTP *)
		return (forw fk x0 false = forw fk x1 true); (* Cf succeeds when this happens *)
	}
}.
\end{easycrypt}

Now, define the claw-finding module type:

\begin{easycrypt}
module type ClawFinder = {
  proc find_claw(fk: fkey) : (D * D)
}.
\end{easycrypt}

Next, define a claw-finding adversary which simulates $\Sim_\Hyb$'s execution and outputs a claw if $\Sim_\Hyb$ aborts.

\begin{easycrypt}
module CFAdv : ClawFinder ( (* has access to Sim_Hyb *) ) = {
	var Sim.x, Sim.x' : D;
	proc find_claw(fk : fkey) : D * D = {

		(* Simulate running Sim_Hyb interacting with an adversary when fk is in the CRS. *)

		if ( (* Sim_Hyb aborts *) ) {
			(* Finding a claw means: forw fk x false = forw fk x true = y *)
			return (Sim.x, Sim.x'); (* Get and return the claw from Sim's memory. *)
		}
		else {
			return (Sim.y, Sim.y); (* Failure to find claw *)
		}
	}
}.
\end{easycrypt}

\section{Hybrid \ref{hyb:2}: Showing $\Hyb \approx \Ideal$}

\subsection{Overview} \label{sec:indcpa_red_overview}
IND-CPA (i.e. semantic) security in a PKE scheme captures the property that the scheme's ciphertexts reveal only a negligible amount of information about their underlying plaintexts. We show that any adversary that distinguishes between $\Hyb$ and $\Ideal$ can be used to win the IND-CPA game (as described in \cref{sec:indcpa}) via a cryptographic reduction.

The outline for the reduction works as follows: Let $p$ be the probability of distinguishing ciphertexts in some IND-CPA PKE scheme. Assume (for a contradiction) that there exists an $\Environment$ distinguishing between $\Hyb$ and $\Ideal$ with probability $> p$. Next, construct an adversary $\IndcpaAdversary$ that wins the IND-CPA security game with a probability that is too high, contradicting the IND-CPA security of the PKE scheme. Thus, we conclude that $\Environment$'s distinguishing advantage is $\leq p$.

First, we describe the difference between $\Hyb$ and $\Ideal$. \megan{Add: argue that apart from $c_{1-b}$, Hyb and Ideal give the same view.}
In $\Hyb$, observe that the $\CommitMsg$ message $(y, c_0, c_1)$ is
\begin{itemize}
	\item $y = \CFPTP.\Forw_{b}(x)$
	\item $c_b = \PKE.\Enc_{pk}(x; r_b)$
	\item $c_{1-b} = \PKE.\Enc_{pk}(0; r_{1-b})$.
\end{itemize}
where $x, r_0, r_1$ are uniformly sampled.

In $\Ideal$, the $\CommitMsg$ message $(y, c_0, c_1)$ is:
\begin{itemize}
	\item $y = \CFPTP.\Forw_{b}(x_b)$
	\item $c_b = \PKE.\Enc_{pk}(x_b; r_b)$
	\item $c_{1-b} = \PKE.\Enc_{pk}(x_{1-b}; r_{1-b})$
\end{itemize}
where $x_0, x_1, r_0, r_1$ are uniformly sampled.

The difference between $\Hyb$ and $\Ideal$ is the encrypted plaintext for $c_{1-b}$. In essence, distinguishing $\Hyb$ and $\Ideal$, means distinguishing between whether $c_{1-b}$ is an encryption of $0$ or $x_{1-b}$.

Hence, given an environment $\Environment$ that distinuguishes between $\Hyb$ and $\Ideal$ with non-negligible probability $>p$, we can construct an adversary $\IndcpaAdversary$ that breaks IND-CPA security. On input the committed bit $b$, $\IndcpaAdversary$ interacts with to a challenger $\IndcpaGM$ and does the following:
\begin{enumerate}
	\item Sample $x_0, x_1, r_0, r_1$ uniformly.
	\item Honestly compute $y = \CFPTP.\Forw_b(x_b)$ and $c_b = \PKE.\Enc_{pk}(x_b; r_b)$.
	\item Send $(0, x_{1-b})$ to $\IndcpaGM$, and receive an encryption $c^*$ of either $0$ or $x_{1-b}$.
	\item Set $c_{1-b} = c^*$.
	\item \megan{Generate the rest of $\Environment$'s view (incl. $\OpenMsg$ message)}.
	\item Send $(y, c_b, c_{1-b})$ to $\Environment$, which outputs a bit indicating ``$\Hyb$'' or ``$\Ideal$''.
	\item If $\Environment$ outputs ``$\Hyb$'' output 0. If $\Environment$ outputs ``$\Ideal$'' output 1.
\end{enumerate}

Here, if $\Environment$ sees that $c_{1-b} = \PKE.\Enc_{pk}(0; r_{1-b})$, it will output $\Hyb$. When $\Environment$ sees that $c_{1-b} = \PKE.\Enc_{pk}(x_{1-b}; r_{1-b})$, it will output $\Ideal$. Hence, $\IndcpaAdversary$ outputs the correct bit with exactly the same probability that $\IndcpaAdversary$ distinguishies between $\Hyb$ and $\Real$. Then since $p$ is non-negligible, this is a contradiction.

\subsection{Easycrypt Proof}
Following the logic from \cref{sec:indcpa_red_overview}, our goal is to show that the $\Environment$'s distinguishing advantange between $\Hyb$ and $\Ideal$ is:

\begin{easycrypt}
lemma HYB_IDEAL &m :
`|Pr[HYB.main() @ &m : res] - Pr[IDEAL.main() @ &m : res]|
<= `|Pr[INDCPA_0(Adv).main() @ &m : res] - Pr[INDCPA_1(Adv).main() @ &m : res]|.
\end{easycrypt}

\subsubsection{IND-CPA Game}\label{sec:indcpa}
The IND-CPA game is formalized in ${\sf Pke.ec}$ via defining two modules \code{INDCPA\_0}, \code{INDCPA\_1} that resspectively encrypt two adversarially chosen plaintexts $x_0, x_1$:

\begin{easycrypt}
	module INDCPA_0(Adv : ADV_INDCPA) = { (* Always encrypts x0 *)
	  proc main() : bool = {
	    var pk : pkey; var sk : skey;
	    var r : rand;
	    var x0, x1 : plaintext;
	    var b : bool;
	    var c : ciphertext;
	    (pk, sk) <$ dkeygen;         (* Generate keys for PKE *)
	    r <$ drand;                  (* Select randomness used in PKE *)
	    (x0, x1) <@ Adv.choose(pk);  (* Adv chooses plaintexts x0, x1 *)
	    c <- enc pk x0 r;            (* Encrypt x0 *)
	    b <@ Adv.main(pk, c);        (* Adv guesses which ciphertext was encrypted *)
	    return b;
	  }
	}.

	module INDCPA_1(Adv : ADV_INDCPA) = { (* Always encrypts x1*)
	  proc main() : bool = {
	    var pk : pkey; var sk : skey;
	    var r : rand;
	    var x0, x1 : plaintext;
	    var b : bool;
	    var c : ciphertext;
	    (pk, sk) <$ dkeygen;         (* Generate keys for PKE *)
	    r <$ drand;                  (* Select randomness used in PKE *)
	    (x0, x1) <@ Adv.choose(pk);  (* Adv chooses plaintexts x0, x1 *)
	    c <- enc pk x1 r;            (* Encrypt x1 *)
	    b <@ Adv.main(pk, c);        (* Adv guesses which ciphertext was encrypted *)
	    return b;
	  }
	}.
\end{easycrypt}

Then, an IND-CPA adversary wins if it correctly guesses which module (\code{INDCPA\_0}, \code{INDCPA\_1}) it is in. We formalize this idea as the adversary's ``advantage'', which is captured as:

\begin{easycrypt}
	`|Pr[INDCPA_0(Adv).main() @ &m : res] - Pr[INDCPA_1(Adv).main() @ &m : res]|
\end{easycrypt}

Next, we build a module for the INDCPA adversary \code{Adv}:

\begin{easycrypt}
module Adv : ADV_INDCPA ( (* has access to the Environment for Hyb vs Ideal game *) ) = {
	var c : plaintext;
	proc choose(pk : pkey) : plaintext * plaintext = {
		x <$ dplaintext;	(* Sample a random plaintext $*)
		return (zero, x)	(* Return two plaintexts: 0 and the one sampled above. *)
	}

	proc main(pk : pkey, c : ciphertext) : bool = {
		(* Query the Hyb / Ideal distinguishing Environment with c. Receive Environment's output guessing whether it's in Hyb or Ideal *)

		if ( (* Environment outputs ``Hyb'' *) ) {
			return 0;	(* Guess that c is an encryption of 0 *)
		}
		else ( (* Environment outputs ``Ideal'' *) ) {
			return 1;	(* Guess that c is an encryption of some plaintext x *)
		}

	}
}.
\end{easycrypt}

{\small{
\bibliographystyle{alpha}
\bibliography{refs}
}}

\end{document}
